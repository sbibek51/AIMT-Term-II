{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f31da94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb79a5",
   "metadata": {},
   "source": [
    "1-Add the custom stopwords “NIL” and “JUNK” in spaCy and remove the stopwords in below text\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\" Jonas was a JUNK great guy NIL Adam was evil NIL Martha JUNK was more of a fool \"\n",
    "Expected \n",
    "Output :'Jonas great guy Adam evil Martha fool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f7c54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    " stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d6ebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['don', 'our', 'doing', 'a', 'ours', 'with', \"don't\", 'd', 'll', 'i']\n"
     ]
    }
   ],
   "source": [
    "stop_words_list = list(stop_words)\n",
    "print(stop_words_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac3021ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Jonas was a JUNK great guy NIL Adam was evil NIL Martha JUNK was more of a fool\n",
      "Output: Jonas great guy Adam evil Martha fool\n"
     ]
    }
   ],
   "source": [
    "# Defining your custom stopwords and convert them to lowercase\n",
    "custom_stopwords = {\"NIL\", \"JUNK\"}\n",
    "custom_stopwords = {word.lower() for word in custom_stopwords}\n",
    "\n",
    "# making a union set of stopwords\n",
    "new_stopwords = stop_words.union(custom_stopwords)\n",
    "\n",
    "# Processing\n",
    "text = \"Jonas was a JUNK great guy NIL Adam was evil NIL Martha JUNK was more of a fool\"\n",
    "filtered_text = \" \".join(word for word in text.split() if word.lower() not in new_stopwords)\n",
    "\n",
    "print(\"Input: \", text)\n",
    "print(\"Output:\", filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678f367",
   "metadata": {},
   "source": [
    "2- Perform stemming/ convert each token to it’s root form in the given text\n",
    "\n",
    "Input :text= \"Dancing is an art. Students should be taught dance as a subject in schools . I danced in many of my school function. Some people are always hesitating to dance.\"\n",
    "text= 'danc is an art . student should be taught danc as a subject in school . I danc in mani of my school function . some peopl are alway hesit to danc .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0db343e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55087788",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"Dancing is an art. Students should be taught dance as a subject in schools . I danced in many of my school function. Some people are always \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9c5b28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "Dancing is an art. Students should be taught dance as a subject in schools . I danced in many of my school function. Some people are always \n",
      "Stemmed Text:\n",
      "danc is an art. student should be taught danc as a subject in school . i danc in mani of my school function. some peopl are alway\n"
     ]
    }
   ],
   "source": [
    "# Stem each word in the text\n",
    "stemmed_text = \" \".join(porter.stem(word) for word in text.split())\n",
    "\n",
    "\n",
    "print(\"Original Text:\")\n",
    "print(text)\n",
    "print(\"Stemmed Text:\")\n",
    "print(stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97636794",
   "metadata": {},
   "source": [
    " How to merge two tokens as one ?\n",
    "Q. Merge the first name and last name as single token in the given sentence\n",
    "\n",
    "Input:\n",
    "\n",
    "text=\"Robert Langdon is a famous character in various books and movies \"\n",
    "Desired Output:\n",
    "\n",
    "\n",
    "Robert Langdon\n",
    "is\n",
    "a\n",
    "famous\n",
    "character\n",
    "in\n",
    "various\n",
    "books\n",
    "and\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac66dae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired Output:\n",
      "Robert\n",
      "Langdon\n",
      "is\n",
      "a\n",
      "famous\n",
      "character\n",
      "in\n",
      "various\n",
      "books\n",
      "and\n",
      "movies\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \"Robert Langdon is a famous character in various books and movies\"\n",
    "\n",
    "name_pattern = re.compile(r'(\\b[A-Z][a-z]+\\b) (\\b[A-Z][a-z]+\\b)')\n",
    "\n",
    "merged_text = name_pattern.sub(r'\\1 \\2', text)\n",
    "\n",
    "merged_tokens = merged_text.split()\n",
    "\n",
    "print(\"Desired Output:\")\n",
    "for token in merged_tokens:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9207a9db",
   "metadata": {},
   "source": [
    "Q.  Write a Python program to search for literal strings within a string.\n",
    "Sample text : 'The quick brown fox jumps over the lazy dog.'\n",
    "Searched words : 'fox', 'dog', 'horse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48b629e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found words: ['fox', 'dog']\n"
     ]
    }
   ],
   "source": [
    "def search_words(text, searched_words):\n",
    "    found_words = []\n",
    "    for word in searched_words:\n",
    "        if word in text:\n",
    "            found_words.append(word)\n",
    "    return found_words\n",
    "\n",
    "# Sample text\n",
    "sample_text = 'The quick brown fox jumps over the lazy dog.'\n",
    "\n",
    "# Searched words\n",
    "searched_words = ['fox', 'dog', 'horse']\n",
    "\n",
    "# Search for words in the text\n",
    "found_words = search_words(sample_text, searched_words)\n",
    "\n",
    "\n",
    "print(\"Found words:\", found_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31a189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
